{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08aff8b",
   "metadata": {},
   "source": [
    "# Getting Started with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0450da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0100fb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=nlp(u'Apple is looking at buting a U.K. startup for $10 Billion')\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75492fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is VERB aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buting VERB pcomp\n",
      "a DET det\n",
      "U.K. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "10 NUM compound\n",
      "Billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:  #pos= part of speech\n",
    "    print(token.text,token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e722b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x7fe5e9556dd0>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x7fe5fa4f1050>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x7fe5fa4f15f0>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d6ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2=nlp(\"Apple isn't looking into buying startups in U.K. anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70435e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple     PROPN     nsubj     \n",
      "is        VERB      aux       \n",
      "n't       ADV       neg       \n",
      "looking   VERB      ROOT      \n",
      "into      ADP       prep      \n",
      "buying    VERB      compound  \n",
      "startups  NOUN      pobj      \n",
      "in        ADP       prep      \n",
      "U.K.      PROPN     pobj      \n",
      "anymore   ADV       advmod    \n",
      ".         PUNCT     punct     \n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(f'{token.text:{10}}{token.pos_:{10}}{token.dep_:{10}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bdbe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d22723b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bbc8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "111a86b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.dep_ #dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "769e5eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e148d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(str(doc[0].pos_))  #proper noun 专有名词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac528a02",
   "metadata": {},
   "source": [
    "## spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fb96310",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commonly attributed to JL from his song \"Beautiful boy\",\\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist AS and published in Reader\\'s Digest in 1957, when L was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abc8748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "life_quote=doc3[12:26]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2738ea",
   "metadata": {},
   "source": [
    "**break your text into sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf2ed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence. <class 'spacy.tokens.span.Span'>\n",
      "Hey, second sentence. <class 'spacy.tokens.span.Span'>\n",
      "Third sentence. <class 'spacy.tokens.span.Span'>\n",
      "Fourth sentence. <class 'spacy.tokens.span.Span'>\n",
      "And stupid sentence. <class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u'This is the first sentence. Hey, second sentence. Third sentence. Fourth sentence. And stupid sentence.')\n",
    "for sentence in doc4.sents:\n",
    "    print(sentence,type(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee589359",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4[0].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6384d690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cebc5f3",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a36ae6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2416c4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "string='\"We\\'re moving to L.A.!\"'\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ac80449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" | We | 're | moving | to | L.A. | ! | \" | "
     ]
    }
   ],
   "source": [
    "doc_new=nlp(string)\n",
    "for token in doc_new:\n",
    "    print(token,end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8415a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "snail\n",
      "-\n",
      "mail\n",
      ",\n",
      "email\n",
      "supporot@oursite.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "at\n",
      "http://www.oursite.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc2=nlp(u\"We're here to help! Send snail-mail, email supporot@oursite.com or visit us at http://www.oursite.com!\")\n",
    "for token in doc2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95ffd934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "paid\n",
      "$\n",
      "9.98\n",
      "for\n",
      "a\n",
      "used\n",
      "furniture\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc3=nlp(u\"I paid $9.98 for a used furniture.\")\n",
    "for token in doc3:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8164e239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St\n",
      ".\n",
      "Louis\n",
      "in\n",
      "U.S.\n",
      "next\n",
      "month\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc4=nlp(u\"Let's visit St.Louis in U.S. next month.\")\n",
    "for token in doc4:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f983ff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visit St."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4596034c",
   "metadata": {},
   "source": [
    "**Doc object does not support assignment** (imutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0cd87ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.doc.Doc' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ly/csbbtbk94zg0bw5rzw4l3cdc0000gn/T/ipykernel_6348/3699060234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Make'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "doc4[0]='Make'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22fc4308",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.doc.Doc' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ly/csbbtbk94zg0bw5rzw4l3cdc0000gn/T/ipykernel_6348/1115506739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'My dinner was horrible.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdoc6\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your dinner was great.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdoc5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "doc5=nlp('My dinner was horrible.')\n",
    "doc6=nlp('Your dinner was great.')\n",
    "doc5[3]=doc6[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c51045",
   "metadata": {},
   "source": [
    "## Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65cf6a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | is | trying | to | build | a | new | factory | in | Hong | Kong | in | 2035 | . | \n",
      "--------------------\n",
      "\n",
      "Apple \t ORG \t Companies, agencies, institutions, etc.\n",
      "Hong Kong \t GPE \t Countries, cities, states\n",
      "2035 \t DATE \t Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "doc8=nlp(u\"Apple is trying to build a new factory in Hong Kong in 2035.\")\n",
    "for token in doc8:\n",
    "    print(token,end=' | ' )\n",
    "    \n",
    "print('\\n--------------------\\n')\n",
    "    \n",
    "for entity in doc8.ents:\n",
    "    print(entity.text,'\\t',entity.label_,'\\t',spacy.explain(str(entity.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eedeb32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc8.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161e978",
   "metadata": {},
   "source": [
    "### Noun Chunks 名词短语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8871759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufacturers\n"
     ]
    }
   ],
   "source": [
    "doc9=nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "793202d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red cars\n",
      "higher insurance rates\n"
     ]
    }
   ],
   "source": [
    "doc10=nlp(u\"Red cars do not carry higher insurance rates.\")\n",
    "for chunk in doc10.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af281654",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a628d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79c397b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"850\" height=\"287.0\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Red</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">cars</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">carry</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">higher</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">insurance</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">rates.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,102.0 140.0,102.0 140.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,2.0 450.0,2.0 450.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M270,152.0 C270,52.0 445.0,52.0 445.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,154.0 L262,142.0 278,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M370,152.0 C370,102.0 440.0,102.0 440.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,154.0 L362,142.0 378,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M570,152.0 C570,52.0 745.0,52.0 745.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570,154.0 L562,142.0 578,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M670,152.0 C670,102.0 740.0,102.0 740.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,154.0 L662,142.0 678,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M470,152.0 C470,2.0 750.0,2.0 750.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,154.0 L758.0,142.0 742.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc10,style='dep',jupyter=True,options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdea4922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc=nlp(u\"Over the last quarter Apple sold nearly 20 thousand iPhones for a profit of $6 million.\")\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24338e88",
   "metadata": {},
   "source": [
    "# Stemming 词干提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0c2066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82597b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangminyue/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8c27594",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de532669",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['run','runs','runner','running','ran','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e6a207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run----->run\n",
      "runs----->run\n",
      "runner----->runner\n",
      "running----->run\n",
      "ran----->ran\n",
      "easily----->easili\n",
      "fairly----->fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'----->'+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfccd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowball stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "770e83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "s_stemmer=SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc56b57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run----->run\n",
      "runs----->run\n",
      "runner----->runner\n",
      "running----->run\n",
      "ran----->ran\n",
      "easily----->easili\n",
      "fairly----->fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'----->'+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86710f",
   "metadata": {},
   "source": [
    "**limitations of stemmers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06b8889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I---->i\n",
      "am---->am\n",
      "meeting---->meet\n",
      "Raj---->raj\n",
      "at---->at\n",
      "the---->the\n",
      "meeting---->meet\n",
      "this---->this\n",
      "afternoon.---->afternoon.\n"
     ]
    }
   ],
   "source": [
    "phrase='I am meeting Raj at the meeting this afternoon.'\n",
    "for word in phrase.split():\n",
    "    print(word+'---->'+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec5d6a",
   "metadata": {},
   "source": [
    "two 'meeting' are not the same meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50729ea3",
   "metadata": {},
   "source": [
    "# Lemmatization 词形还原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f61644d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t -PRON-\n",
      "am \t VERB \t be\n",
      "a \t DET \t a\n",
      "runner \t NOUN \t runner\n",
      "running \t VERB \t run\n",
      "in \t ADP \t in\n",
      "a \t DET \t a\n",
      "race \t NOUN \t race\n",
      "because \t ADP \t because\n",
      "I \t PRON \t -PRON-\n",
      "lover \t VERB \t lover\n",
      "to \t PART \t to\n",
      "run \t VERB \t run\n",
      "and \t CCONJ \t and\n",
      "I \t PRON \t -PRON-\n",
      "ran \t VERB \t run\n",
      "earlier \t ADV \t earlier\n",
      "this \t DET \t this\n",
      "morning \t NOUN \t morning\n",
      ". \t PUNCT \t .\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"I am a runner running in a race because I lover to run and I ran earlier this morning.\")\n",
    "for token in doc:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6c658b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(doc):\n",
    "    for token in doc:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3803554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   -PRON-\n",
      "am           VERB   be\n",
      "a            DET    a\n",
      "runner       NOUN   runner\n",
      "running      VERB   run\n",
      "in           ADP    in\n",
      "a            DET    a\n",
      "race         NOUN   race\n",
      "because      ADP    because\n",
      "I            PRON   -PRON-\n",
      "lover        VERB   lover\n",
      "to           PART   to\n",
      "run          VERB   run\n",
      "and          CCONJ  and\n",
      "I            PRON   -PRON-\n",
      "ran          VERB   run\n",
      "earlier      ADV    earlier\n",
      "this         DET    this\n",
      "morning      NOUN   morning\n",
      ".            PUNCT  .\n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "918ef65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   -PRON-\n",
      "saw          VERB   see\n",
      "18           NUM    18\n",
      "mice         NOUN   mouse\n",
      "today        NOUN   today\n",
      "and          CCONJ  and\n",
      "six          NUM    six\n",
      "mice         NOUN   mouse\n",
      "yesterday    NOUN   yesterday\n",
      ".            PUNCT  .\n"
     ]
    }
   ],
   "source": [
    "doc2=nlp(u\"I saw 18 mice today and six mice yesterday.\")\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cecf413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   -PRON-\n",
      "do           VERB   do\n",
      "not          ADV    not\n",
      "know         VERB   know\n",
      "whether      ADP    whether\n",
      "4-grams      NOUN   4-gram\n",
      "or           CCONJ  or\n",
      "trigrams     NOUN   trigram\n",
      "is           VERB   be\n",
      "better       ADJ    good\n"
     ]
    }
   ],
   "source": [
    "doc_x=nlp(u\"I do not know whether 4-grams or trigrams is better\")\n",
    "show_lemmas(doc_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1007025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That         DET    that\n",
      "'s           VERB   be\n",
      "an           DET    an\n",
      "enormous     ADJ    enormous\n",
      "automobile   NOUN   automobile\n",
      ".            PUNCT  .\n"
     ]
    }
   ],
   "source": [
    "doc3=nlp(\"That's an enormous automobile.\")\n",
    "show_lemmas(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0471fcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That         DET    that\n",
      "was          VERB   be\n",
      "ridiculously ADV    ridiculously\n",
      "easy         ADJ    easy\n",
      "and          CCONJ  and\n",
      "esaily       ADV    esaily\n",
      "done         VERB   do\n",
      "and          CCONJ  and\n",
      "fairly       ADV    fairly\n",
      ".            PUNCT  .\n"
     ]
    }
   ],
   "source": [
    "doc4=nlp(u\"That was ridiculously easy and esaily done and fairly.\")\n",
    "show_lemmas(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a79a4",
   "metadata": {},
   "source": [
    "# stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e13a037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'as', 'beside', 'has', 'until', 'full', 'former', 'itself', 'neither', 'you', 'however', 'again', 'between', 'throughout', 'eleven', 'seems', 'due', 'onto', 'fifty', 'give', 'seemed', 'no', 'formerly', 'please', 'towards', 'another', 'three', 'did', 'became', 'an', 'hereafter', 'off', 'ours', 'latter', 'all', 'are', 'behind', 'now', 'our', 'yourselves', 'ca', 'really', 'go', 'most', 'seem', 'someone', 'above', 'though', 'never', 'one', 'become', 'see', 'yet', 'show', 'name', 'same', 'out', 'when', 'much', 'nevertheless', 'whatever', 'him', 'make', 'first', 'down', 'not', 'then', 'wherever', 'hers', 'into', 'top', 'part', 'rather', 'through', 'your', 'quite', 'yourself', 'whither', 'regarding', 'in', 'but', 'cannot', 'should', 'keep', 'six', 'under', 'bottom', 'perhaps', 'themselves', 'many', 'moreover', 'others', 'indeed', 'even', 'ourselves', 'mostly', 'eight', 'toward', 'us', 'its', 'somewhere', 'such', 'there', 'do', 'third', 'just', 'i', 'were', 'anyway', 'everything', 'else', 'more', 'whole', 'does', 'sometimes', 'here', 'during', 'than', 'himself', 'without', 'this', 'front', 'for', 'so', 'thru', 'where', 'together', 'therefore', 'we', 'anything', 'have', 'anyhow', 'yours', 'elsewhere', 'may', 'nine', 'my', 'almost', 'wherein', 'via', 'by', 'they', 'beforehand', 'get', 'two', 'over', 'empty', 'of', 'or', 'how', 'made', 'had', 'her', 'from', 'herself', 're', 'amount', 'around', 'would', 'ever', 'she', 'can', 'besides', 'been', 'thereby', 'whereafter', 'latterly', 'once', 'last', 'with', 'because', 'otherwise', 'might', 'say', 'am', 'thence', 'will', 'amongst', 'well', 'whom', 'next', 'their', 'other', 'twelve', 'twenty', 'thereafter', 'serious', 'everyone', 'on', 'must', 'noone', 'whereas', 'why', 'doing', 'at', 'various', 'anyone', 'further', 'move', 'being', 'mine', 'four', 'whereby', 'each', 'nobody', 'whose', 'hereby', 'the', 'few', 'a', 'something', 'very', 'whence', 'if', 'often', 'to', 'who', 'hence', 'since', 'could', 'after', 'sixty', 'nothing', 'these', 'meanwhile', 'every', 'hundred', 'thereupon', 'against', 'back', 'be', 'thus', 'using', 'always', 'somehow', 'was', 'enough', 'side', 'ten', 'take', 'therein', 'before', 'both', 'about', 'whereupon', 'becoming', 'hereupon', 'me', 'forty', 'also', 'per', 'fifteen', 'none', 'below', 'own', 'still', 'that', 'is', 'except', 'several', 'across', 'namely', 'whenever', 'some', 'least', 'nowhere', 'put', 'up', 'within', 'them', 'he', 'whoever', 'already', 'along', 'and', 'alone', 'anywhere', 'beyond', 'his', 'it', 'call', 'while', 'too', 'herein', 'what', 'whether', 'used', 'seeming', 'sometime', 'five', 'myself', 'only', 'upon', 'less', 'unless', 'afterwards', 'which', 'those', 'although', 'either', 'everywhere', 'any', 'nor', 'done', 'among', 'becomes'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d6c247d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['whenever'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "707b6802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['teacher'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "539939af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00972493",
   "metadata": {},
   "source": [
    "**two steps to set a new word into stop word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b92f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b683ad59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7669551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['btw'].is_stop=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3458106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ae28c",
   "metadata": {},
   "source": [
    "**remove a word from default(such same as add)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2ade85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.remove('btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0171f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['btw'].is_stop=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c08875b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e92019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
